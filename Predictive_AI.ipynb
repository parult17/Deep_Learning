{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Psn-z1duUNmA"
      },
      "source": [
        "### Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULpxRHv-UNmA"
      },
      "outputs": [],
      "source": [
        "# Importing torch packages\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "import torchvision.models as models\n",
        "\n",
        "# Importing other packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor\n",
        "x = torch.tensor([[1, 2], [3, 4]])\n",
        "print(\"Tensor x:\\n\", x)"
      ],
      "metadata": {
        "id": "hniKPTeBYaoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor operations\n",
        "y = torch.ones(2, 2)\n",
        "print(\"Tensor y:\\n\", y)\n",
        "z = x + y\n",
        "print(\"x + y:\\n\", z)"
      ],
      "metadata": {
        "id": "WYBhG8sfYbid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Autograd\n",
        "# Requires_grad flag for automatic differentiation\n",
        "x = torch.tensor([[1., 2.], [3., 4.]], requires_grad=True)\n",
        "y = torch.tensor([[5., 6.], [7., 8.]], requires_grad=True)\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "A_7mEXOUYez2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computation\n",
        "z = x + y\n",
        "print(\"z:\\n\", z)"
      ],
      "metadata": {
        "id": "A_zDe-vuYoch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing gradients\n",
        "t = torch.sum(z)\n",
        "t.backward()\n",
        "\n",
        "# Accessing gradients\n",
        "print(\"Gradient of x:\\n\", x.grad)\n",
        "print(\"Gradient of y:\\n\", y.grad)"
      ],
      "metadata": {
        "id": "SMkzGeGCYtwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Univariate Linear Regression"
      ],
      "metadata": {
        "id": "-1IyIAmWDHbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the sample data"
      ],
      "metadata": {
        "id": "lALh8VvjT5qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating a sample dataset\n",
        "np.random.seed(0)\n",
        "X_uni = np.random.rand(100, 1) * 10  # Years of experience (between 0 and 10)\n",
        "y_uni = 3 * X_uni + 2 + np.random.randn(100, 1)  # Salary, with some noise"
      ],
      "metadata": {
        "id": "4mpRs-E7B3m_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the data\n",
        "plt.scatter(X_uni, y_uni, label='Data')\n",
        "plt.xlabel('Years of Experience')\n",
        "plt.ylabel('Salary')\n",
        "plt.legend()\n",
        "plt.title('Sample Dataset')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dM2-_zGF6TGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to PyTorch tensors\n",
        "X_uni_tensor = torch.tensor(X_uni, dtype=torch.float32)\n",
        "y_uni_tensor = torch.tensor(y_uni, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "r9KRWnJ2gquj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Linear Regression model\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "mOjWUY48gtME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the model\n",
        "model = LinearRegressionModel()"
      ],
      "metadata": {
        "id": "t9Sb4i7egw02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and the optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "JjhywLLngvd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()  # Zero the gradients\n",
        "    outputs = model(X_uni_tensor)  # Forward pass\n",
        "    loss = criterion(outputs, y_uni_tensor)  # Compute the loss\n",
        "    loss.backward()  # Backward pass\n",
        "    optimizer.step()  # Update the weights\n",
        "\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "Rt3CWUiZg0R2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_tensor = model(X_uni_tensor)"
      ],
      "metadata": {
        "id": "Kl1XWm-Zg38p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert predictions to numpy array\n",
        "y_pred = y_pred_tensor.numpy()"
      ],
      "metadata": {
        "id": "1Y5F9gKZg5vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the model coefficients\n",
        "print(\"Intercept:\", model.linear.bias.item())\n",
        "print(\"Coefficient:\", model.linear.weight.item())"
      ],
      "metadata": {
        "id": "u2OY-j0wg7P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the results\n",
        "plt.scatter(X_uni, y_uni, color='blue', label='Original data')\n",
        "plt.plot(X_uni, y_pred, color='red', label='Fitted line')\n",
        "plt.xlabel('Years of Experience')\n",
        "plt.ylabel('Salary')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CaW0BsBschae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHj_ZREiqvxU"
      },
      "outputs": [],
      "source": [
        "# To test whether GPU instance is present in the system or not.\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('Using PyTorch version:', torch.__version__, 'CUDA:', use_cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_WeWksDqvxb"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Multivariate Classification"
      ],
      "metadata": {
        "id": "Sfupwo8FANgq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hillq61ILyG5"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),])\n",
        "\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
        "\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),])"
      ],
      "metadata": {
        "id": "LHmCYjbFwRvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=20, shuffle=True)\n",
        "\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=20, shuffle=True)"
      ],
      "metadata": {
        "id": "w9Cog-rJw214"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (X_train, y_train) in train_loader:\n",
        "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
        "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
        "    break"
      ],
      "metadata": {
        "id": "2SguqdsHxHTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXXtfQXgmEO7"
      },
      "source": [
        "## Plotting the images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels =[]\n",
        "features = []\n",
        "for X,y in zip(X_train, y_train):\n",
        "  # Getting unique labels\n",
        "  if y not in labels:\n",
        "    labels.append(y)\n",
        "    features.append(X)\n",
        "\n",
        "pltsize=1\n",
        "plt.figure(figsize=(7,7))\n",
        "for i in range(5):\n",
        "    plt.subplot(3,3, i+1)\n",
        "    plt.axis('off')\n",
        "    # Convert the tensor to numpy for displaying the image\n",
        "    plt.imshow(features[i].numpy().reshape(28,28), cmap=\"gray\")\n",
        "    plt.title(f'Label: {labels[i]}')"
      ],
      "metadata": {
        "id": "yNbOwsMMxrSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_ey0gh9UNmJ"
      },
      "source": [
        "### Dense Neural Network Classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEYZoawOppFN"
      },
      "source": [
        "## Defining the Dense Neural Networkâ€™s Architecture"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)  # Flatten the image\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ExHDyD98WtB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlTLMs5Q-6Uh"
      },
      "source": [
        "#### Calling the instances of the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5DecLBbmnYC"
      },
      "outputs": [],
      "source": [
        "model = Model()\n",
        "model = model.to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3RpbpWiJkJr"
      },
      "outputs": [],
      "source": [
        "summary(model, input_size=(1,28,28), batch_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgJQ6bNG-Mx0"
      },
      "source": [
        "#### Defining the loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjUUgDMQmw7Y"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmNz24u_n5fw"
      },
      "source": [
        "#### Training and Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG_e4hjdrgs7"
      },
      "outputs": [],
      "source": [
        "# No of Epochs\n",
        "epoch = 2\n",
        "\n",
        "# keeping the network in train mode\n",
        "model.train()\n",
        "train_losses,  train_accuracy = [], []\n",
        "\n",
        "# Loop for no of epochs\n",
        "for e in range(epoch):\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    # Iterate through all the batches in each epoch\n",
        "    for images, labels in train_loader:\n",
        "\n",
        "      # Convert the image and label to gpu for faster execution\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # Zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Passing the data to the model (Forward Pass)\n",
        "      outputs = model(images)\n",
        "\n",
        "      # Calculating the loss\n",
        "      loss = criterion(outputs, labels)\n",
        "      train_loss += loss.item()\n",
        "\n",
        "      # Performing backward pass (Backpropagation)\n",
        "      loss.backward()\n",
        "\n",
        "      # optimizer.step() updates the weights accordingly\n",
        "      optimizer.step()\n",
        "\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Accuracy calculation\n",
        "    train_losses.append(train_loss/len(mnist_trainset))\n",
        "    train_accuracy.append(100 * correct/len(mnist_trainset))\n",
        "    print('epoch: {}, Train Loss:{:.6f} Train Accuracy: {:.2f} '.format(e+1,train_losses[-1], train_accuracy[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEZPsRndr1i9"
      },
      "outputs": [],
      "source": [
        "# Keeping the network in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "Test_accuracy = 0\n",
        "\n",
        "# Iterate through all the batches in each epoch\n",
        "for images,labels in test_loader:\n",
        "\n",
        "    # Convert the images and labels to gpu for faster execution\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Do the forward pass\n",
        "    outputs = model(images)\n",
        "\n",
        "    # Accuracy calculation\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    Test_accuracy += (predicted == labels).sum().item()\n",
        "\n",
        "Accuracy = 100 * Test_accuracy / len(mnist_testset)\n",
        "print(\"Accuracy of Test Data is\", Accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKm6IXufWM8U"
      },
      "source": [
        "## Transfer Learning with Pretrained Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMbIq3rZlrUO"
      },
      "source": [
        "### Visualizing one image from the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jB7EQosBovSk"
      },
      "outputs": [],
      "source": [
        "# Iterate through the testloader and extract one image and label\n",
        "for images, labels in test_loader:\n",
        "  image = images[0]  # Take the first image from the batch\n",
        "  label = labels[0]  # Take the corresponding label\n",
        "  break  # Exit the loop after extracting one sample\n",
        "\n",
        "# Print the shape of the image and the label\n",
        "print(\"Image shape:\", image.shape)\n",
        "print(\"Label:\", label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eL7FRzBwpEvr"
      },
      "outputs": [],
      "source": [
        "# Reshape the image to [1, 1, 28, 28]\n",
        "image_reshaped = image.unsqueeze(0)  # Add a batch dimension\n",
        "print(\"Reshaped image shape:\", image_reshaped.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAv5etOeqeIs"
      },
      "outputs": [],
      "source": [
        "# Convert the tensor to numpy for displaying the image\n",
        "image_np = image_reshaped.squeeze().numpy()  # Remove batch dimension and convert to numpy\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image_np, cmap='gray')\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OXjvs-imOkR"
      },
      "source": [
        "### Load ResNet50 model and fine-tune it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uUyPEWKPiw7"
      },
      "outputs": [],
      "source": [
        "# Load pretrained ResNet50 model\n",
        "model = models.resnet50(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6-5eQswbPaQ"
      },
      "outputs": [],
      "source": [
        "# Modify the final fully connected layer to match the number of classes in Fashion MNIST\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "# Move the model to the device (GPU if available)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8Y4ug5asKV-"
      },
      "source": [
        "Training is expected to take time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7C3kIKkcTtn"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "epoch = 2\n",
        "model.train()\n",
        "train_losses, train_accuracy = [], []\n",
        "\n",
        "for e in range(epoch):\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    for images, labels in train_loader:\n",
        "        resize_transform = transforms.Resize((224, 224))\n",
        "        resized_image = resize_transform(images)\n",
        "        resized_image = resized_image.repeat(1, 3, 1, 1)\n",
        "        images = resized_image.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    train_losses.append(train_loss / len(mnist_trainset))\n",
        "    train_accuracy.append(100 * correct / len(mnist_trainset))\n",
        "    print('epoch: {}, Train Loss:{:.6f} Train Accuracy: {:.2f} '.format(e + 1, train_losses[-1], train_accuracy[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stTeFTEscF-u"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "model.eval()\n",
        "Test_accuracy = 0\n",
        "\n",
        "for images, labels in test_loader:\n",
        "    resize_transform = transforms.Resize((224, 224))\n",
        "    resized_image = resize_transform(images)\n",
        "    resized_image = resized_image.repeat(1, 3, 1, 1)\n",
        "    images = resized_image.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    Test_accuracy += (predicted == labels).sum().item()\n",
        "\n",
        "Accuracy = 100 * Test_accuracy / len(mnist_testset)\n",
        "print(\"Accuracy of Test Data is\", Accuracy)"
      ]
    }
  ]
}